{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeto final da cadeira IF807 que tem como o objetivo a implementação de uma técnica dentro do tema de Fairness em sistemas de recomendação. A técnica é baseada em um artigo que pode ser encontrado nesse link: https://dl.acm.org/doi/10.1145/3292500.3330691"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equipe:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo é implementar um sistema de re-ranqueamento que consideram o Fainess, para que então ocorra menos viéses na hora de gerar listas de ranking em algoritmos de recomendação. Com essa proposta, esse viés é quantificado e mitigado, para um determinado subconjunto de dados, esses algoritmos podem gerar uma distribuição desejada dos resultados mais bem classificados, mantendo assim a paridade demográfica ou a igualdade de oportunidades conforme necessário. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As métricas são definidas para avaliar o nível de Fairness então alcançado e são mostrador resultados obtidos através de dados sinteticamente gerados que buscam replicar uma aplicação prática de uma busca de talentos do LinkedIn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas para avaliação de viés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O artigo lista algumas medidas que podem ser utilizadas para obter o valor de viés de cada um dos algoritmos de recomendação, eles são definidos como o seguinte:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Medidas baseada nos top-k resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skew@k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Desvio dos top-k resultados rankeados da proporção desejada é quantificada usando uma métrica skew (assimetria). A função log retorna um valor negativo de assimetria para under representation ou positiva para over representation do atributo que está sendo avaliado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion_calc(df,k,ai):\n",
    "    count=0\n",
    "    for i in range(k):  \n",
    "        if (df[i] == ai): \n",
    "            count = count+1\n",
    "    return (count/k)    \n",
    "\n",
    "def skew_func(df,p,k,ai):\n",
    "    s = math.log((proportion_calc(df,k,ai)+1)/(p[ai]+1)) \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A métrica acima tem alguns problemas, primeiro o fato de que é definida apenas sobre o valor de um atributo e precisa ser estendida para aglobar vários, e também, o valor computado depende altamente do valor k (top valores) e então uma métrica acumulativa e compreensiva é requerida. Para resolver esses problemas, são definidas métricas MinSkew e MaxSkew que quantificam a pior desvantagem e maior vantagem para um candidato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MinSkew@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_skew(df,p,k):\n",
    "    min_skew_var=float('inf')\n",
    "    for x in range(len(p)):\n",
    "        m=skew_func(list(df),p,k,x)\n",
    "        if m < min_skew_var:\n",
    "            min_skew_var = m\n",
    "    return min_skew_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MaxSkew@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_skew(df,p,k):\n",
    "    max_skew_var=-float('inf')\n",
    "    for x in range(len(p)):\n",
    "        m=skew_func(list(df),p,k,x)\n",
    "        if m > max_skew_var:\n",
    "            max_skew_var = m\n",
    "    return max_skew_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o segundo problema citado acima, métricas de ranqueamento são definidas e listadas abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas de ranqueamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NDKL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A divergência Kullback-Leibler (KL) é uma medida não negativa no qual o valor maior denota uma grande divergência entre as distribuições, ela é implementada como uma medida acumulativa envolvendo uma média baseada em pesos de Skew@i sobre todos os valores de atributo.\n",
    "\n",
    "Um viés de magnitude igual mas em direções opostas não pode ser distinguido por essa métrica, por isso ele não indica qual atributo está sendo tratado de forma injusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kld_func(D1,D2):\n",
    "    a = np.asarray(D1, dtype=np.float)\n",
    "    b = np.asarray(D2, dtype=np.float)\n",
    "\n",
    "    return np.sum(np.where(a != 0 , a * np.log((a +0.00001)/(b+0.00001)), 0))\n",
    "\n",
    "def ndkl_func(df,p):\n",
    "    Z = np.sum(1/(np.log2(np.arange(1,len(df)+1)+1)))\n",
    "    total=0\n",
    "\n",
    "    for i in range(1,len(df)+1): \n",
    "        value=df[:i].value_counts(normalize = True)\n",
    "        value=value.to_dict()\n",
    "        D1=[]\n",
    "        for i in range(len(p)):\n",
    "            if i in value.keys():\n",
    "                D1.append(value[i])\n",
    "            else:\n",
    "                D1.append(0)\n",
    "        total=total+(1/math.log2(i+1)) * kld_func(D1,p)\n",
    "\n",
    "    return (1/Z)*total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ganho de desconto acumulativo normalizado, o ganho cumulativo captura que os resultados muito relevantes são mais úteis do que os resultados parcialmente relevantes, que, por sua vez, são mais úteis do que os resultados irrelevantes. Dependendo da noção de relevância, que para o caso do teste é o score de cada candidato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0\n",
    "\n",
    "def ndcg_at_k(df, k, method=0):\n",
    "    r=list(df)\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propriedades desejadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para garantir uma representação justa nos resultados top-k de uma lista classificada, é importante que a proporção de cada atributo protegido (como gênero ou raça) esteja dentro de limites específicos. Se qualquer top-k violar essas proporções mínimas, o sistema é considerado inviável. Duas medidas ajudam a avaliar isso: o Índice Inviável, que conta quantas vezes qualquer top-k quebra a regra de representação mínima, e a Contagem Inviável, que contabiliza todas as violações de representação mínima em cada posição top-k. Essas métricas podem ser ajustadas para diferentes tamanhos de listas e quantidades de atributos para garantir comparações justas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infeasible_index(df, p):\n",
    "    \n",
    "    # Parâmetros e variáveis iniciais\n",
    "    data = df[:100]\n",
    "    num_attributes = len(p)\n",
    "    tao_r = 100\n",
    "    inf_index_tao_r = 0\n",
    "    inf_count_tao_r = 0\n",
    "\n",
    "    # Iterar sobre cada top-k\n",
    "    for k in range(1, tao_r + 1):\n",
    "        data_temp_k = data[:k]\n",
    "        infeasible_flag = False\n",
    "\n",
    "        # Verificar cada valor de atributo protegido\n",
    "        for i, desired_proportion in enumerate(p):\n",
    "            observed_count_ai = (data_temp_k['ai'] == i).sum()\n",
    "            desired_count_ai = math.floor(desired_proportion * k)\n",
    "\n",
    "            # Atualizar flags e contadores se a condição mínima não for atendida\n",
    "            if observed_count_ai < desired_count_ai:\n",
    "                infeasible_flag = True\n",
    "                inf_count_tao_r += 1\n",
    "\n",
    "        # Incrementar índice inviável se houver uma violação\n",
    "        if infeasible_flag:\n",
    "            inf_index_tao_r += 1\n",
    "\n",
    "    # Mensagem de erro caso o índice inviável seja maior que 99\n",
    "    if inf_index_tao_r > 99:\n",
    "        print(f\"Erro em {num_attributes} e é: {inf_index_tao_r}\")\n",
    "\n",
    "    return [inf_index_tao_r, inf_count_tao_r]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos de re-Ranqueamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DetGreedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo DetGreedy funciona assim:\n",
    "\n",
    "Primeiro, se a representação mínima de um atributo protegido não está sendo cumprida, selecione o item com a maior pontuação disponível.\n",
    "Caso contrário, selecione o item com a maior pontuação disponível entre os que ainda não atingiram o limite máximo de representação.\n",
    "Atenção: Embora este algoritmo busque maximizar as pontuações dentro de cada grupo de atributos protegidos, ele pode acabar violando as restrições de representação, tornando a lista final inviável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_greedy(data,p,k_max):\n",
    "    rankedAttList = [] \n",
    "    rankedScoreList = []\n",
    "    counts={}\n",
    "    for i in range(len(p)):\n",
    "        counts[i]=0\n",
    "    for k in range(1,k_max+1):\n",
    "        belowMin = {ai for ai,v in counts.items() if v < math.floor(k*p[ai]) }\n",
    "        belowMax = {ai for ai,v in counts.items() if v >= math.floor(k*p[ai]) and v <math.ceil(k*p[ai]) }\n",
    "        s={}\n",
    "        if len(belowMin) != 0:\n",
    "            for i in belowMin:\n",
    "                s[i]=data[(i,counts[i])]\n",
    "            nextAtt = max(s,key=s.get)\n",
    "        else:\n",
    "            for i in belowMax:\n",
    "                s[i]=data[(i,counts[i])]\n",
    "            nextAtt = max(s,key=s.get)\n",
    "        rankedAttList.append(nextAtt)\n",
    "        rankedScoreList.append(data[(nextAtt,counts[nextAtt])])\n",
    "        counts[nextAtt]+=1\n",
    "        \n",
    "    return pd.DataFrame(list(zip(rankedAttList, rankedScoreList)),columns =['ai', 'score']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DetCons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo DetCons é utilizado para verificar a consistência de um conjunto de restrições binárias em problemas de satisfação de restrições (CSP). Ele revisa cada restrição binária para garantir que nenhum valor possa ser removido de um domínio de variável sem violar a consistência dessa restrição. Este processo é repetido até que nenhum valor possa ser removido sem quebrar a consistência de alguma restrição, assegurando assim a solução consistente do CSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_cons(data,p,kmax):\n",
    "\n",
    "    rankedAttrList=[]\n",
    "    rankedScoreList=[]\n",
    "    counts={}\n",
    "    for i in range(len(p)):\n",
    "        counts[i]=0\n",
    "    \n",
    "    for k in range(1,kmax+1):\n",
    "        belowMin = {ai for ai,v in counts.items() if v < math.floor(k*p[ai]) }\n",
    "        belowMax = {ai for ai,v in counts.items() if v >= math.floor(k*p[ai]) and v <math.ceil(k*p[ai]) }\n",
    "        s={}\n",
    "        if len(belowMin)!=0:\n",
    "            for i in belowMin:\n",
    "                s[i]=data[(i,counts[i])]\n",
    "            nextAtt= max(s,key=s.get)\n",
    "                \n",
    "        else: \n",
    "            s={}\n",
    "            for i in belowMax:\n",
    "                s[i]=math.ceil(i*p[i])/p[i]\n",
    "                \n",
    "            nextAtt= min(s,key=s.get)\n",
    "                \n",
    "        rankedAttrList.append(nextAtt)\n",
    "        rankedScoreList.append(data[(nextAtt,counts[nextAtt])])\n",
    "        counts[nextAtt]+=1\n",
    "        \n",
    "    return pd.DataFrame(list(zip(rankedAttrList, rankedScoreList)),columns =['ai', 'score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
